{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ow_0FBCq2E53"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Wb6eQTQ02NnH"
   },
   "outputs": [],
   "source": [
    "emails = pd.read_csv(\"https://raw.githubusercontent.com/musakanneh/spam_classifier/main/spam_or_not_spam.csv\", encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Ht6H8yx72RpU",
    "outputId": "7f4a0997-7f94-4bde-8332-5a9a958d820a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>martin a posted tassos papadopoulos the greek ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man threatens explosion in moscow thursday aug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klez the virus that won t die already the most...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in adding cream to spaghetti carbonara which ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  label\n",
       "0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n",
       "1  martin a posted tassos papadopoulos the greek ...      0\n",
       "2  man threatens explosion in moscow thursday aug...      0\n",
       "3  klez the virus that won t die already the most...      0\n",
       "4   in adding cream to spaghetti carbonara which ...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wajTr-UJ-XJp"
   },
   "outputs": [],
   "source": [
    "# Converting \"email\" data_type to \"Object\"\n",
    "emails['email'] = emails['email'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0o_Ix373g-u"
   },
   "source": [
    "    # Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AB24Y03F3gUq"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = emails['email']\n",
    "y = emails['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJC0fm1I3T1f"
   },
   "source": [
    "    # Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "G_N_Mw2G2S44"
   },
   "outputs": [],
   "source": [
    "# Functions to remove hyperlink, number, punctuations, white space, new_lines, and make the text lower.\n",
    "\n",
    "def remove_hyperlink(word):\n",
    "    return  re.sub(r\"http\\S+\", \"\", word)\n",
    "\n",
    "def to_lower(word):\n",
    "    result = word.lower()\n",
    "    return result\n",
    "\n",
    "def remove_number(word):\n",
    "    result = re.sub(r'\\d+', '', word)\n",
    "    return result\n",
    "\n",
    "def remove_punctuation(word):\n",
    "    result = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
    "    return result\n",
    "\n",
    "def remove_whitespace(word):\n",
    "    result = word.strip()\n",
    "    return result\n",
    "\n",
    "def replace_newline(word):\n",
    "    return word.replace('\\n','')\n",
    "\n",
    "def clean_up_pipeline(sentence):\n",
    "    cleaning_utils = [to_lower,\n",
    "                      replace_newline,\n",
    "                      to_lower,\n",
    "                      remove_number,\n",
    "                      remove_punctuation,remove_whitespace]\n",
    "    for o in cleaning_utils:\n",
    "        sentence = o(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mrS371Pi9Ug2"
   },
   "outputs": [],
   "source": [
    "x_train = [clean_up_pipeline(email) for email in X_train]\n",
    "x_test = [clean_up_pipeline(email) for email in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lkpXGJyYAnKj"
   },
   "source": [
    "        Tokenizing the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZmrdPxloAsJu"
   },
   "outputs": [],
   "source": [
    "# Configuration values\n",
    " \n",
    "embed_size = 100 # Size of each word vector\n",
    "max_feature = 50000 # Number of unique words to use\n",
    "max_len = 2000 # Max number of words to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vohfIDukBFbt"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_feature)\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_features = np.array(tokenizer.texts_to_sequences(X_train))\n",
    "X_test_features = np.array(tokenizer.texts_to_sequences(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52m6lO6oBp_u"
   },
   "source": [
    "        Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "qUJ35qPFBrgC"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_features = pad_sequences(X_train_features, maxlen=max_len)\n",
    "X_test_features = pad_sequences(X_test_features, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDShmNmKBti9",
    "outputId": "38c364f6-dbf5-405f-afae-8dd89007e134"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0, ...,   347, 11438,   230], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4B0xXip2CPPk"
   },
   "source": [
    "    # Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4OpbbCVCS8q",
    "outputId": "b7c2e7b5-12fa-4a54-8c91-e848b093bbac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 2000, 32)          1600000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               49664     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,651,745\n",
      "Trainable params: 1,651,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Necessary Imports for Keras\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "# create the model\n",
    "import tensorflow as tf\n",
    "embedding_vecor_length = 32\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(max_feature, embedding_vecor_length, input_length=max_len))\n",
    "model.add(Bidirectional(tf.keras.layers.LSTM(64)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23MUZZGeCxkJ",
    "outputId": "7e0c0640-edef-489b-e85c-9a16c7af213c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.6888 - accuracy: 0.8340"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_features, y_train, batch_size=512, epochs=20, validation_data=(X_test_features, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiK1hi7MLQ7v"
   },
   "source": [
    "      Visualizing Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "S5ON4WhyLTEv",
    "outputId": "7f479fb2-3a7f-4b94-8d1d-9c978579c5a7"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVC9NfbVMPD4"
   },
   "outputs": [],
   "source": [
    "preds  = [1 if o > 0.5 else 0 for o in model.predict(X_test_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lk0haQooMZ6c",
    "outputId": "3bf28557-1e2d-4110-c4d5-d9f21a3b4a38"
   },
   "outputs": [],
   "source": [
    "confn_matrix = confusion_matrix(y_test, preds)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, preds)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, preds)))\n",
    "print(\"F1 Score: {:.2f}%\".format(100 * f1_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBb1C8NuM7Ac",
    "outputId": "acebc246-3dad-4b37-b5b3-5aeee14c6871"
   },
   "outputs": [],
   "source": [
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "jFl4yv8BLjLH",
    "outputId": "7e901413-2601-4074-aad0-f5f04dc67ce0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(confn_matrix, annot=True, ax = ax,cmap='Blues',fmt=''); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');\n",
    "ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Not Spam', 'Spam']); ax.yaxis.set_ticklabels(['Not Spam', 'Spam']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFLnIPR_NB1B"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "spam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
